---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.13.0
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

```{python}
# %autosave 0

import torch

seed = 1
```

```{python}
import os


data_dir = '/home/gabi/diplomka/code/info-nas/data/'
print(os.listdir(data_dir))
```

```{python}
from nasbench import api

nasbench_path = os.path.join(data_dir, 'nasbench_only108.tfrecord')
nb = api.NASBench(nasbench_path)
```

```{python}
nb_dataset = os.path.join(data_dir, 'nb_dataset.json')
cifar = os.path.join(data_dir, 'cifar')
```

```{python}
torch.multiprocessing.set_sharing_strategy('file_system')

from heatmap_utils import get_labeled_data


dataset_pt = os.path.join(data_dir, 'train_long.pt')
data = get_labeled_data(dataset_pt, nb, nb_dataset, cifar)
```

```{python}
hashes = set()

for d in data:
    hashes.update(d['hash'])
hashes
```

```{python}
from info_nas.config import load_json_cfg
from info_nas.models.utils import get_hash_accuracy

config = load_json_cfg('../configs/model_config.json')

accuracies = get_hash_accuracy(hashes, nb, config)
```

```{python}
import numpy as np
times = []

for h in hashes:
    t = [n['final_training_time'] for n in nb.get_metrics_from_hash(h)[1][12]]
    times.append(np.mean(t))

print(sum(times))
```

```{python}
print(max(accuracies))
```

```{python}
import seaborn as sns
import matplotlib.pyplot as plt
sns.set(font_scale=1.5)
save_dir = '/home/gabi/Dropbox/automl-conf/LatexTemplate/img'

plt.figure(figsize=(7,6))
sns.histplot(accuracies)
plt.xlim(0.79, 0.95)
plt.title("Test accuracy distribution of 608 train networks.")
plt.tight_layout()
plt.savefig(f"{save_dir}/accdist.png")
plt.show()
```

```{python}
from heatmap_utils import get_pred_and_orig

top_k = 10
orig, info, _, labels = get_pred_and_orig(data, device=torch.device('cpu'), top_k=top_k,
                                         )#batch_stop=1001)
```

```{python}
import matplotlib.pyplot as plt
import seaborn as sns
sns.set()

from heatmap_utils import plot_single_heatmap, heatmap_diff

vmin = 0
vmax = 1
o = orig[:1000]

save_dir = '/home/gabi/Dropbox/automl-conf/LatexTemplate/img'

plot_single_heatmap(o, sub_mean=False, by_row=True, vmin=vmin, vmax=vmax)
plt.xlabel('Top 10 features (0 most important)')
plt.title('Output of one network on all images')
plt.ylabel('Image')
plt.xlabel('Top 10 features (0 most important)')
plt.savefig(f"{save_dir}/heat1net.png")
plt.show()
```

```{python}
plot_single_heatmap(orig[0::1000], sub_mean=False, by_row=True, vmin=vmin, vmax=vmax)
plt.title('Output of all networks on one image')
plt.ylabel('Network')
plt.xlabel('Top 10 features (0 most important)')
plt.savefig(f"{save_dir}/heat1img.png")
plt.show()
```

```{python}
o_2 = orig[5000:6000]

plot_single_heatmap(o_2, sub_mean=False, by_row=True, vmin=vmin, vmax=vmax)
plt.show()

heatmap_diff(o, o_2, sub_mean=False, by_row=True, plot_it=True, use_sq=True)
plt.show()
```

```{python}
orig.shape
```

```{python}
import itertools
import numpy as np

k = 0
n_nets = 608
# n_nets = 100
print_freq = 1000
normalize_columns = False

from_feats = norm_orig if normalize_columns else orig
res_matrix = np.zeros((n_nets, n_nets))

divsigma = False
submean = False

for i, j in itertools.combinations(range(n_nets), 2):
    if k % print_freq == 0:
        print(i, j)
    k += 1
        
    if i == j:
        continue

    o = from_feats[i * 1000:(i + 1) * 1000]
    o_2 = from_feats[j * 1000:(j + 1) * 1000]
    diff = heatmap_diff(o, o_2, sub_mean=submean, div_by_sigma=divsigma, by_row=True, plot_it=False, use_sq=True)
    
    diff = np.sum(diff, axis=1)
    diff = diff.mean()
    
    res_matrix[i, j] = diff
```

```{python}
from heatmap_utils import plot_hist


plt.title(f"Error histogram with sigma division turned {'on' if divsigma else 'off'}")
flat = res_matrix.flatten()
flat = flat[flat > 0]
plot_hist(flat)
plt.show()
```

```{python}
print(np.quantile(flat, 0.25))
np.median(flat)
```

```{python}
sns.boxplot(x=flat)
plt.show()
```

```{python}
for i, j in itertools.combinations(range(n_nets), 2):
    res_matrix[j, i] = max(res_matrix[i, j], 0)
```

```{python}
plt.figure(figsize=(12, 12))
plot_single_heatmap(res_matrix)
plt.show()
```

```{python}
plt.figure(figsize=(15,15))
plot_single_heatmap((res_matrix < 0.3).astype(int))
plt.show()
```

```{python}
for th in np.arange(0, 1, 0.1):
    
    km = AgglomerativeClustering(n_clusters=None, linkage='complete', affinity='precomputed', distance_threshold=th)
    res = km.fit_predict(res_matrix)
    uniq = np.unique(res, return_counts=True)
    
    print(round(th, 1), ' | ', sum(uniq[1] == 1), ', clusters > 2: ', sum(uniq[1] > 2))
```

```{python}
from sklearn.cluster import AgglomerativeClustering

thres = 0.4


km = AgglomerativeClustering(n_clusters=None, linkage='complete', affinity='precomputed', distance_threshold=thres)
res = km.fit_predict(res_matrix)
```

```{python}
uniq = np.unique(res, return_counts=True)
print(uniq)
print(sum(uniq[1] == 1))
```

```{python}
cls = 2
print(np.arange(n_nets)[res == cls])
```

```{python}
def get_net_accuracy(net_id, what='test'):
    what = f"final_{what}_accuracy"
    
    net_hash = info['hash'][net_id * 1000]
    metrics = nb.get_metrics_from_hash(net_hash)
    
    return np.mean([m[what] for m in metrics[1][108]])
```

```{python}
accs = [get_net_accuracy(i, what='test') for i in range(n_nets)]
print("mean ", np.mean(accs), "| std ", np.std(accs))
```

```{python}
import pandas as pd


acc_df = []

for cluster_no, cluster_size in zip(*np.unique(res, return_counts=True)):
    if cluster_size == 1:
        continue
    
    print(cluster_no, cluster_size)
    
    net_ids = [i for i, v in enumerate(res) if v == cluster_no]
    #print(net_ids)
    accs = [get_net_accuracy(i, what='test') for i in net_ids]
    
    if cluster_size > 2:
        
        for a in accs:
            acc_df.append({'cluster': cluster_no, 'acc': a})
    
    print("mean ", np.mean(accs), "| std ", np.std(accs), "| max ", np.max(accs))
    print()
    #print(accs)
    print('----------------')
    
acc_df = pd.DataFrame(acc_df)
```

```{python}
save_dir = '/home/gabi/Dropbox/automl-conf/LatexTemplate/img'

sns.set(font_scale=1.4)
plt.figure(figsize=(15, 6))
plt.title(f'Accuracies of networks clustered by top {top_k} features, threshold {thres}')

sns.boxplot(data=acc_df, x='cluster', y='acc')
sns.stripplot(data=acc_df, x='cluster', y='acc', color=".25", alpha=0.6)
plt.ylim(0.79, 0.95)
plt.ylabel('Accuracy')
plt.xlabel('Cluster number')
plt.tight_layout()
plt.savefig(f"{save_dir}/cluster.png")
plt.show()
```

```{python}
nb.get_metrics_from_hash(info['hash'][0])
```

```{python}
nb.get_metrics_from_hash(info['hash'][462000])
```

```{python}

```
