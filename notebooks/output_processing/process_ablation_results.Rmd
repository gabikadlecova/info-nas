---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.13.0
      jupytext_formats: ipynb,Rmd:rmarkdown
  kernelspec:
    display_name: bioinf
    language: python
    name: bioinf
---

```{python}
# %autosave 0
```

```{python}
import os
import pandas as pd

res_path = '/home/gabi/diplomka/results/'
base_names = ['labeled_train', 'labeled_valid_unseen_networks-val_loss', 'labeled_valid_unseen_images-val_loss']

def process_res_directory(dir_path: str, with_baselines=True):
    loss_df = pd.read_csv(os.path.join(dir_path, 'loss.csv'), index_col=0)
    labeled_train = loss_df[['labeled_labeled']]
    unlabeled_train = loss_df[['labeled_unlabeled']]
    ununlabeled_train = loss_df[['unlabeled_unlabeled']]
    
    metrics_df = pd.read_csv(os.path.join(dir_path, 'metrics.csv'), index_col=0)
    metric_cols = [c for c in metrics_df.columns]
    
    labeled_val = metrics_df[metric_cols]
                            
    res_df = pd.concat([labeled_train, unlabeled_train, ununlabeled_train, labeled_val], axis=1)
    res_df.reset_index(inplace=True)
    
    exp_name = dir_path.split('/')[-3]
    res_df.insert(0, 'exp_name', exp_name)
    
    if with_baselines:
        baselines = {}
        base_files = ['train_long_baseline.csv', 'valid_long_baseline.csv', 'test_small_split_baseline.csv']
        for name, baseline in zip(base_names, base_files):
            baseline_path = os.path.join(dir_path, baseline)
            base_df = pd.read_csv(baseline_path, index_col=0)

            baselines[name] = base_df

        return exp_name, res_df, baselines
    
    return exp_name, res_df
```

```{python}
import glob

dfs = []
baseline_dict = {}

for dir_p in glob.glob(os.path.join(res_path, 'model_config*/2021-19-07_13*/')):
    name, res, base = process_res_directory(dir_p)
    
    dfs.append(res)
    baseline_dict[name] = base
    
dfs = pd.concat(dfs)
```

```{python}
dfs[dfs['index'] == 8]
```

```{python}
print(dfs[dfs['index'] == 8][[c for c in dfs.columns if 'acc' in c or 'exp' in c]].round(4).to_latex())
```

```{python}
def get_comparison_for_epoch(full_df, reference, epoch):
    preserve_columns = ['labeled_unlabeled', 'validity', 'labeled_labeled', 'unlabeled_unlabeled', 'exp_name', 'index']
    #columns = [c for c in full_df.columns if 'val_loss' in c or c in preserve_columns]
    columns = [c for c in full_df.columns if 'L1' in c or 'val_loss' in c or c in preserve_columns]
    
    filtered_df = full_df[columns]
    filtered_df = filtered_df[filtered_df['index'] == epoch].reset_index(drop=True)
    res_df = []
    
    for i, exp_name in enumerate(filtered_df['exp_name']):
        res_entry = {}
        
        if 'vae' in exp_name:
            vae = exp_name[17:21]
            vae = 1.0 if '1.0' in vae else float(vae)
            labeled = float(exp_name[29:31].replace('-', ''))
            
            if labeled == 0:
                labeled = 0.5
            elif labeled == 5:
                labeled = 50.0
            
            res_entry['labeled_labeled_scaled'] = filtered_df.iloc[i]['labeled_labeled'] / labeled
            res_entry['labeled_unlabeled_scaled'] = filtered_df.iloc[i]['labeled_unlabeled'] / vae
            res_entry['unlabeled_unlabeled_scaled'] = filtered_df.iloc[i]['unlabeled_unlabeled'] / vae
            for c in filtered_df.columns:
                if 'labeled_valid' not in c or 'name' in c:
                    continue
                res_entry[f"{c}_scaled"] = filtered_df.iloc[i][c] / labeled
        else:
            labeled = 1.0
        
        exp_ref = reference[exp_name]
        for b in base_names:
            b_df = exp_ref[b]
                        
            use_id = 0 if 'MSE' in exp_name else 1
            res_entry.update({f"{b}_{k}_ref": v for k, v in b_df.iloc[use_id].iteritems()})
            
            
        res_df.append(res_entry)
    
    res_df = pd.DataFrame(res_df)
    res_df = pd.concat([filtered_df, res_df], axis=1)
    res_df = res_df.reindex(sorted(res_df.columns), axis=1)
    return res_df
```

```{python}
i = 8
rd = get_comparison_for_epoch(dfs, baseline_dict, i).round(8)
rd.to_csv(f'expe_data/epoch_{i}_w_baselines.csv')
```

```{python}
rd.reindex(sorted(rd.columns), axis=1)
```

```{python}
sorted(rd.columns)
```

```{python}

```

```{python}
im_paths = glob.glob(os.path.join(res_path, 'model_config_loss-MSE_lr-1e-4.json/*/'))
im_paths
```

```{python}
im1_name, im1_res, base = process_res_directory(im_paths[0])
im2_name, im2_res = process_res_directory(im_paths[1], with_baselines=False)
```

```{python}
base
```

```{python}
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

val_loss = im1_res['labeled_valid_unseen_networks-val_loss']
val_loss_std = im1_res['labeled_valid_unseen_networks-val_loss_std']
val_loss2 = im2_res['labeled_valid_unseen_networks-val_loss']
val_loss2_std = im2_res['labeled_valid_unseen_networks-val_loss_std']
val_base = base['labeled_valid_unseen_networks-val_loss'].iloc[1]['mean']
val_base_std = base['labeled_valid_unseen_networks-val_loss'].iloc[1]['std']

plt.figure()
plt.plot(val_loss)
plt.fill_between(np.arange(len(val_loss)), val_loss + val_loss_std, val_loss - val_loss_std, alpha=0.3)
plt.plot(val_loss2)
plt.fill_between(np.arange(len(val_loss2)), val_loss2 + val_loss2_std, val_loss2 - val_loss2_std, alpha=0.2)
plt.hlines(val_base, 0, len(val_loss), colors='r')
plt.show()
```

```{python}
im_paths = glob.glob(os.path.join(res_path, 'model_config_loss-L1_lr-1e-3.json/*/'))

im1_name, im1_res, base = process_res_directory(im_paths[0])
im2_name, im2_res = process_res_directory(im_paths[1], with_baselines=False)

im_paths
```

```{python}
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

val_loss = im1_res['labeled_valid_unseen_networks-val_loss']
val_loss_std = im1_res['labeled_valid_unseen_networks-val_loss_std']
val_loss2 = im2_res['labeled_valid_unseen_networks-val_loss']
val_loss2_std = im2_res['labeled_valid_unseen_networks-val_loss_std']
val_base = base['labeled_valid_unseen_networks-val_loss'].iloc[1]['mean']
val_base_std = base['labeled_valid_unseen_networks-val_loss'].iloc[1]['std']

plt.figure()
plt.plot(val_loss)
plt.fill_between(np.arange(len(val_loss)), val_loss + val_loss_std, val_loss - val_loss_std, alpha=0.3)
plt.plot(val_loss2)
plt.fill_between(np.arange(len(val_loss2)), val_loss2 + val_loss2_std, val_loss2 - val_loss2_std, alpha=0.2)
plt.hlines(val_base, 0, len(val_loss), colors='r')
plt.show()
```

```{python}

```

```{python}
rd8 = get_comparison_for_epoch(dfs, baseline_dict, 8)
rd20 = get_comparison_for_epoch(dfs, baseline_dict, 20)
rd30 = get_comparison_for_epoch(dfs, baseline_dict, 30)
```

```{python}
train_samples = 608000
val_samples = 77000
test_samples = 122000

def ci_95(std, sample_size):
    return 1.96 * std / np.sqrt(sample_size)
```

```{python}
import numpy as np

def replace_with_scaled(df, normal_column_name, scaled_column):
    for i, val in scaled_column.iteritems():
        if not pd.isna(val):
            #print(i)
            df.loc[i, normal_column_name] = val

def rename_expe(name):
    name = name.replace('model_config_', '').replace('.json', '')
    name = ', '.join(name.split('_'))
    name = ': '.join(name.split('-'))
    return name

def get_epoch_stats_train(rd):
    lossn = 'labeled_valid_unseen_images-val_loss_loss_name_ref'
    lu = 'labeled_unlabeled'
    uu = 'unlabeled_unlabeled'
    mean_train = rd[['exp_name', lossn, uu, lu, 'labeled_labeled', 'labeled_train_mean_ref']].copy()
    ci_ref = ci_95(rd['labeled_train_std_ref'], train_samples)
    mean_train['ci'] = ci_ref
    
    mean_train.columns = [(c if c != lossn else 'loss name') for c in mean_train.columns]
    
    replace_with_scaled(mean_train, 'labeled_unlabeled', rd['labeled_unlabeled_scaled'])
    replace_with_scaled(mean_train, 'labeled_labeled', rd['labeled_labeled_scaled'])
    mean_train['exp_name'] = [rename_expe(e) for e in mean_train['exp_name']]
    
    return mean_train

def get_epoch_stats_val(rd, name, samples, new_name):
    mean_val = rd[f'{name}']
    mean_ref = rd[f'{name}_mean_ref']
    ci = ci_95(rd[f'{name}_std'], samples)
    ci_ref = ci_95(rd[f'{name}_std_ref'], samples)
    
    df = pd.concat([mean_val, ci, mean_ref, ci_ref], axis=1)
    df.columns = [f"{new_name}_mean", f"{new_name}_ci", f"{new_name}_mean_ref", f"{new_name}_ci_ref"]
    
    replace_with_scaled(df, f'{new_name}_mean', rd[f'{name}_scaled'])
    
    return df
   
in_rd = rd8
res = get_epoch_stats_train(in_rd)
resv = get_epoch_stats_val(in_rd, 'labeled_valid_unseen_networks-val_loss', val_samples, 'unseen_networks')
rest = get_epoch_stats_val(in_rd, 'labeled_valid_unseen_images-val_loss', test_samples, 'unseen_images')
res = pd.concat([res, resv, rest], axis=1).round(4)
print(' '.join([w for w in res.to_latex(index=False).split(' ') if len(w)]))
res
```

```{python}
rd8.columns
```

```{python}
scaling_new_comparison = rd8[['exp_name', 'labeled_valid_unseen_networks-val_loss', 'labeled_valid_unseen_networks-val_loss_std',
    'labeled_valid_unseen_networks-val_loss_mean_ref', 'labeled_valid_unseen_networks-val_loss_std_ref']][
    rd8['exp_name'].str.contains('weighted')
]
```

```{python}
scaling_new_comparison
```

```{python}
scaling_new_comparison['labeled_valid_unseen_networks-val_loss'] / scaling_new_comparison['labeled_valid_unseen_networks-val_loss_std']
```

```{python}
scaling_new_comparison['labeled_valid_unseen_networks-val_loss_mean_ref'] / scaling_new_comparison['labeled_valid_unseen_networks-val_loss_std_ref']
```

```{python}
rd8[['exp_name', 'labeled_valid_unseen_networks-L1', 'labeled_valid_unseen_images-L1']]
```

```{python}
print(' '.join([w for w in res[['exp_name', 'labeled_unlabeled', 'unlabeled_unlabeled']].to_latex(index=False).split(' ') if len(w)]))
```

```{python}
for i, a in rd8['labeled_valid_unseen_images-val_loss'].iteritems():
    print(i)
```

```{python}
rd8['labeled_valid_unseen_images-val_loss']
```

```{python}
a = """0, false, false    & L1 & 0.0017 & $0.0017 \pm 0.0000$  & $0.0016   \pm 0.0000$ & $0.0016  \pm 0.0000$ & $0.0018 \pm 0.0000$ & $0.0018 \pm 0.0000$\\
0, false, true     & L1 & 0.0436 & $0.0855 \pm 0.0000$  & $117.44  \pm 5.5340$ & $234.38 \pm 5.5087$ & $0.0448 \pm 0.0000$ & $0.0877 \pm 0.0000$ \\
0, true, true      & L1 & 0.6474 & $0.7131 \pm 0.0001$  & $0.6637   \pm 0.0006$ & $0.6980  \pm 0.0005$ & $0.7331 \pm 0.0007$ & $0.7707 \pm 0.0003$\\
null, false, false & L1 & 1.8351 & $2.0912 \pm 0.0004$  & $1.9465   \pm 0.0021$ & $2.0696  \pm 0.0017$ & $2.1036 \pm 0.0024$ & $2.2572 \pm 0.0011$\\
null, false, true  & L1 & 0.1815 & $0.7656 \pm 0.0003$  & $0.3824   \pm 0.0020$ & $0.7106  \pm 0.0037$ & $0.2106 \pm 0.0008$ & $0.7254 \pm 0.0006$\\
null, true, true   & L1 & 0.5520 & $0.6691 \pm 0.0002$  & $0.6012   \pm 0.0007$ & $0.6717  \pm 0.0007$ & $0.6463 \pm 0.0008$ & $0.7404 \pm 0.0004$\\
L1, 1e: 2          & L1 & 0.7542 & $0.7656 \pm 0.0003$  & $0.7046   \pm 0.0040$ & $0.7106  \pm 0.0037$ & $0.7256 \pm 0.0034$ & $0.7254 \pm 0.0006$\\
L1, 1e: 3          & L1 & 0.1818 & $0.7656 \pm 0.0003$  & $0.4080   \pm 0.0022$ & $0.7106  \pm 0.0037$ & $0.2292 \pm 0.0009$ & $0.7254 \pm 0.0006$\\
 L1, 1e: 4         & L1 & 0.1771 & $0.7656 \pm 0.0003$  & $0.4165   \pm 0.0025$ & $0.7106  \pm 0.0037$ & $0.1369 \pm 0.0002$ & $0.7254 \pm 0.0006$\\
 MSE, 1e: 2       & MSE & 0.2836 & $1.0002 \pm 0.0007$  & $0.3603   \pm 0.0032$ & $0.8346  \pm 0.0080$ & $0.3400 \pm 0.0035$ & $0.9585 \pm 0.0019$\\
MSE, 1e: 3        & MSE & 0.0832 & $1.0002 \pm 0.0007$  & $0.2894   \pm 0.0030$ & $0.8346  \pm 0.0080$ & $0.1506 \pm 0.0009$ & $0.9585 \pm 0.0019$\\
MSE, 1e: 4        & MSE & 0.0804 & $1.0002 \pm 0.0007$  & $0.1964   \pm 0.0015$ & $0.8346  \pm 0.0080$ & $0.0764 \pm 0.0003$ & $0.9585 \pm 0.0019$\\
1.0, 0.5           & L1 & 0.1864 & $0.7656 \pm 0.0003$  & $0.3861   \pm 0.0010$ & $0.7106  \pm 0.0037$ & $0.2320 \pm 0.0005$ & $0.7254 \pm 0.0006$\\
1.0, 1             & L1 & 0.1788 & $0.7656 \pm 0.0003$  & $0.3598   \pm 0.0016$ & $0.7106  \pm 0.0037$ & $0.2128 \pm 0.0009$ & $0.7254 \pm 0.0006$\\
1.0, 3             & L1 & 0.1749 & $0.7656 \pm 0.0003$  & $0.3856   \pm 0.0064$ & $0.7106  \pm 0.0037$ & $0.1822 \pm 0.0022$ & $0.7254 \pm 0.0006$\\
1.0, 50            & L1 & 0.1772 & $0.7656 \pm 0.0003$  & $0.4287   \pm 0.1257$ & $0.7106  \pm 0.0037$ & $0.2082 \pm 0.0425$ & $0.7254 \pm 0.0006$\\
1e: 2, 0.5         & L1 & 0.1796 & $0.7656 \pm 0.0003$  & $0.3817   \pm 0.0011$ & $0.7106  \pm 0.0037$ & $0.1775 \pm 0.0003$ & $0.7254 \pm 0.0006$\\
1e: 2, 1           & L1 & 0.1773 & $0.7656 \pm 0.0003$  & $0.3905   \pm 0.0021$ & $0.7106  \pm 0.0037$ & $0.1717 \pm 0.0006$ & $0.7254 \pm 0.0006$\\
1e: 2, 3           & L1 & 0.1796 & $0.7656 \pm 0.0003$  & $0.3978   \pm 0.0067$ & $0.7106  \pm 0.0037$ & $0.1752 \pm 0.0023$ & $0.7254 \pm 0.0006$\\
1e: 2, 50          & L1 & 0.1861 & $0.7656 \pm 0.0003$  & $0.3746   \pm 0.0869$ & $0.7106  \pm 0.0037$ & $0.1678 \pm 0.0176$ & $0.7254 \pm 0.0006$\\
1e: 4, 0.5         & L1 & 0.1814 & $0.7656 \pm 0.0003$  & $0.4273   \pm 0.0011$ & $0.7106  \pm 0.0037$ & $0.1654 \pm 0.0002$ & $0.7254 \pm 0.0006$\\
1e: 4, 1           & L1 & 0.1797 & $0.7656 \pm 0.0003$  & $0.3306   \pm 0.0015$ & $0.7106  \pm 0.0037$ & $0.1784 \pm 0.0005$ & $0.7254 \pm 0.0006$\\
1e: 4, 3           & L1 & 0.1808 & $0.7656 \pm 0.0003$  & $0.3361   \pm 0.0051$ & $0.7106  \pm 0.0037$ & $0.1701 \pm 0.0009$ & $0.7254 \pm 0.0006$\\
1e: 4, 50          & L1 & 0.1812 & $0.7656 \pm 0.0003$  & $0.3426   \pm 0.0834$ & $0.7106  \pm 0.0037$ & $0.1632 \pm 0.0158$ & $0.7254 \pm 0.0006$\\"""
a = [b.split('&') for b in a.split('\n')]
print('\n'.join([' & '.join(b) for b in np.array(a)[:6].T.tolist()]))
```

```{python}

```
